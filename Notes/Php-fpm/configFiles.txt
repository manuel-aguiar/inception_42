# **************************************************************************** #
#                                                                              #
#                                                         :::      ::::::::    #
#    configFiles.txt                                    :+:      :+:    :+:    #
#                                                     +:+ +:+         +:+      #
#    By: mmaria-d <mmaria-d@student.42lisboa.com    +#+  +:+       +#+         #
#                                                 +#+#+#+#+#+   +#+            #
#    Created: 2024/10/31 18:17:45 by mmaria-d          #+#    #+#              #
#    Updated: 2024/10/31 18:31:42 by mmaria-d         ###   ########.fr        #
#                                                                              #
# **************************************************************************** #

[www]                                           <- pool name
user = www-data
group = www-data
listen = 0.0.0.0:${PORT_LISTEN_WORDPRESS}
listen.owner = www-data
listen.group = www-data
listen.mode = 0660
pm = dynamic
pm.max_children = 5
pm.start_servers = 2
pm.min_spare_servers = 1
pm.max_spare_servers = 3
php_admin_value[error_log] = /var/log/php7.x-fpm.log
php_admin_flag[log_errors] = on


pools:
    pools are groups of processes with certain characteristics. For instance if the same php-fpm server (daemon)
    is serving multiple php requests from different places or you want to segregate more child processes
    for certain hot pages, you can define them here.

    Then in nginx, you would take that hot page (like index.html) and segregate it via the "location" directive
    and tell it to forward fastcgi to that particular socket or port
        (port must be different between pools, otherwise there is conflict of data......)
        (or different unix sockets, like php-default.sock and php-hot.sock, etc)
    
    in my case, i'll make my life easy and have a single entry point for the whole website
    but if i were to analyse traffic i would have to segregate and allocate more child processes and workers
    to "hotter" pages, like index for instance

[inception]                                           <- pool name
user = www-inception-data
group = www-inception-data
listen = 0.0.0.0:${PORT_LISTEN_WORDPRESS}
listen.owner = www-inception-data
listen.group = www-inception-data
listen.mode = 0660                                      <- permissions to access the lsitening socket file
pm = dynamic
pm.max_children = 5                                     <- this and below concern child processes, max, start, min idle, max idle
pm.start_servers = 2
pm.min_spare_servers = 1
pm.max_spare_servers = 3
php_admin_value[error_log] = /var/log/php7.x-fpm.log    <- log file
php_admin_flag[log_errors] = on

getting the php version
# php -v | head -n 1 | cut -d ' ' -f 2 | cut -d '.' -f -2
sudo systemctl status php$(php -v | head -n 1 | cut -d ' ' -f 2 | cut -d '.' -f -2)-fpm
